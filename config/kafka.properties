#kafka集群ip+port端口,多个以逗号隔开
kafka.servers=192.168.30.128:9092,192.168.30.129:9092,192.168.30.130:9092
#是否自动提交
kafka.consumer.enable.auto.commit=true
#连接超时时间
kafka.consumer.session.timeout=20000
#自动提交间隔
kafka.consumer.auto.commit.interval=100
#开始消费earliest 最早，latest 最新
kafka.consumer.auto.offset.reset=earliest
#消费组
kafka.consumer.group.id=consumer-1
#消费线程数一般与partition相同或者小于partition数(自动提交有用,手动提交配置多线程会导致消息重复消费)
kafka.consumer.concurrency=3

#批量消费大小
kafka.consumer.max-poll-records=100

#重试次数
kafka.producer.retries=1
#批量大小
kafka.producer.batch.size=4096
#基于时间的批量策略
kafka.producer.linger=1
#缓存大小
kafka.producer.buffer.memory=40960

#消息重置offset(https://blog.csdn.net/u010003835/article/details/83314766)

#如何保证kafka消息顺序消费几种方法
# 1、每个topic1个partition,1个消费线程
# 2、多个partition下，把需要顺序消费的消息数据丢入同一个partition,一个消费线程
# 3、多个partition下，把需要顺序消费的消息数据的key设置为一样,一个消费线程


# kafka 配置文件详解http://kafka.apache.org/documentation/#configuration
#1、kafka的分区副本数不能超过 broker数
#2、kafka集群至少2台，zoopkeeper集群必须3台(zab)
#3、分区与副本 每个topic 3 partition,2个副本，都产生 3 * 2 的文件夹来存储；分区不同，数据不同；每个分区的所有副本做选举，isr:与leader分区数据接近的副本分区
#4、partition - segement - index,log(每个文件的大小可以由参数log.segment.byte决定) , index文件每条记录的offset是跳跃的,log文件存储消息文件
#5、每个log文件的名字由上一个log文件最后一个offset+1 确定
#6、kafka查找消息流程 offset 二分查找 到 index与log文件，
# 通过index文件与offset找到物理偏移position 日志起始范围,然后在log文件从该position向下查找每条消息的offset的值与目标值相等的那条
#7、由于启动两台kafka集群，其中一台挂机，导致消费消息失败，经发现需要server.properties设置offsets.topic.replication.factor, transaction.state.log.replication.factor 设置为broker的数量
#且删除__consumer_offsets topic(./kafka-topics.sh --bootstrap-server 192.168.80.100:9092 --delete --topic __consumer_offsets)重启kafka集群
#8、消费组过期时间配置 offsets.retention.minutes 默认 10080(7天) ,offsets.retention.check.interval.ms 默认 10分钟